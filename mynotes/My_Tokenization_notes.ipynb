{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Text pre-processing for Machine Learning Algorithms\n",
    "\n",
    "Text cannot be used directly for any Text-processing or NLP algorithms. Text need to be preprossed so that it become suitable for the algorithms. The Bag of the Words (BoW) model is used in machine learning. BoW focuses on the occurance of words rather than the order. This can be done by assigning each word a unique number and then any text can be encoded with the fixed size vector of known words. For example\n",
    "\n",
    "    Vocab -           am, new, boy, a, and....\n",
    "    Assigned Number - 1,  2,   3,  4,   5, ..........\n",
    "    Intial Vector   { 0 , 0 , 0 , 0 , 0 , 0.....}\n",
    "\n",
    "    Now the text - I am a boy and I am new\n",
    "    In this text, 'I' has occured once. Similary 'am', 'a', 'boy'. So, 'I' has occured twice so in the vector the first position will be incremented to 2. Same thing is done for other words\n",
    "             am  new  boy  a  and  ....\n",
    "    Vector {  2,  1,    1,  1,  1 }\n",
    "\n",
    "In reality, the vocab is too big and many times there are many 0s in the vector. The scikit-learn library provides 3 different schemes that we can use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Word Counts with CountVectorizer\n",
    "\n",
    "### Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "You can use it as follows:\n",
    "\n",
    "    1) Create an instance of the CountVectorizer class.\n",
    "    2) Call the fit() function in order to learn a vocabulary from one or more documents.\n",
    "    3) Call the transform() function on one or more documents as needed to encode each as a vector.\n",
    "    \n",
    " Because these vectors will contain a lot of zeros, we call them sparse. Python provides an efficient way of handling sparse vectors in the scipy.sparse package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'am': 0, 'boy': 2, 'and': 1, 'new': 3}\n",
      "(1, 4)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[2 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# list of text documents\n",
    "text = [\"I am a boy and I am new.\"]\n",
    "\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
